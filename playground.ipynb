{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import deepdish as dd\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8dce9fc2252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/pos_freq.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/biology'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "data = dd.io.load('data/pos_freq.h5', '/biology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = nltk.probability.ConditionalFreqDist()\n",
    "\n",
    "for d in data:\n",
    "    tags += d['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 'binding-sites', 'translation', 'ribosome', 'synthetic-biology']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['tags'].conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJ': 3466,\n",
       "          'ADP': 34,\n",
       "          'ADV': 121,\n",
       "          'CONJ': 2,\n",
       "          'DET': 32,\n",
       "          'NOUN': 28278,\n",
       "          'NUM': 67,\n",
       "          'PRON': 1,\n",
       "          'PRT': 1,\n",
       "          'VERB': 1127})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags = tags.conditions()\n",
    "\n",
    "pos = nltk.FreqDist()\n",
    "\n",
    "for t in all_tags:\n",
    "    pos += tags[t]\n",
    "    \n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = data[0]['content'].conditions()[0]\n",
    "print(word)\n",
    "data[0]['content'][word]['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"list\") to tuple",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-d9ae0a0e2d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mn_content\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_types\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"list\") to tuple"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "pos_types = {'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN','NUM', 'PRON','PRT','VERB'}\n",
    "\n",
    "columns = ['word'] + ['-'.join(['T', p]) for p in pos_types] + ['-'.join(['C', p]) for p in pos_types]\n",
    "\n",
    "predictors = pd.DataFrame(columns=columns)\n",
    "n_content = ()\n",
    "\n",
    "for w in data[10]['content'].conditions():\n",
    "    n_content += ([data[10]['content'][w][p] for p in pos_types])\n",
    "\n",
    "print(n_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with nltk ##\n",
    "\n",
    "(http://www.ling.helsinki.fi/kit/2012s/clt237/nltk-02-2-print.shtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emma_text = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "emma_bigrams = nltk.bigrams(emma_text)\n",
    "emma_cfd = nltk.ConditionalFreqDist(emma_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to generate 100 words of random Emma-like text: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quietness of finishing his dear father depends , favourably placed all became acquainted ?\" was sent , four o \\' departure of two men he say , deceived herself ? Ladies can I make this parcel for evil were highly of survey ; my heart completely misspent , indeed !-- why Miss W ., it --( speaking a value of beauties .\" [ Emma .\" These delays . Little Henry cut up towards oppressed worth their comfort in direct in want him knives were offering his military life ?\" Jane writes one arm drawn her doom already given us'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_model(cfdist, word, num=15):\n",
    "    words = []\n",
    "    for i in range(num):\n",
    "        words.append(word)\n",
    "        possible_words = list(cfdist[word])\n",
    "        word = random.choice(possible_words)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "        \n",
    "generate_model(emma_cfd, 'The', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a conditional frequency distribution of all the bigrams in Melville's novel Moby Dick, like this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_text = nltk.corpus.gutenberg.words('melville-moby_dick.txt')\n",
    "moby_bigrams = nltk.bigrams(moby_text)\n",
    "moby_cfd = nltk.ConditionalFreqDist(moby_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate 100 words of random Moby Dick-like text: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The previous voyage most folks is stark alone now sheering off like silent , canals and Squires . Most statistical tables of Benjamin Franklin was using my meaning of hearing by we sound was gone perhaps most -- so goes off like cavity is firmly against the 15th chapter but swear that enemy had received into its affrighted moisture in constant use poor Starbuck in new made this seemed Ahab exclaimed Stubb goes all heard in various nations with slouched Ahab of retarding his visiting captain says old routine again his tawny features , driven in Henry VIIIth ' Thou\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_model(moby_cfd, 'The', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixed_cfd = moby_cfd + emma_cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The warmly ; gained such comparatively slow heaving in we escape his impetuousness upon some lack the skipper parading his luckless mate for lonely pride , ON BANKS \\' dare a decidedly more disposed of forgetting for light upon investigation we stuffed a promise . Colonel Campbell might plunge into CHAPTERS ), induce long !\" Instantly all directed to prove but God which also ; hardly separate subject !-- For during the hugest of commotion on those black eyes . Strictly speaking her drawing her boats attacking Sperm Whale so at one difficulty to engage for catching cold by corpusants'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_model(mixed_cfd, 'The', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}